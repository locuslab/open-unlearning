# @package _global_

defaults:
  - override /model: Qwen2.5-3B-Instruct-lora
  - override /trainer: finetune
  - override /data/datasets@data.train: TOFU_QA_full
  - override /eval: tofu

mode: finetune

trainer:
  args:
    learning_rate: 2e-4  # Higher learning rate for LoRA
    weight_decay: 0.01
    warmup_epochs: 0.1
    num_train_epochs: 3
    per_device_train_batch_size: 4
    per_device_eval_batch_size: 4
    gradient_accumulation_steps: 4
    logging_steps: 10
    save_steps: 500
    eval_steps: 500
    evaluation_strategy: steps
    save_strategy: steps
    load_best_model_at_end: false  # Disable to avoid metric issues
    save_total_limit: 2
    remove_unused_columns: false
    dataloader_pin_memory: false
    seed: 42

forget_split: forget10
holdout_split: holdout10
retain_logs_path: null

eval:
  tofu:
    forget_split: ${forget_split}
    holdout_split: ${holdout_split}
    retain_logs_path: ${retain_logs_path}
    overwrite: true

task_name: tofu_Qwen2.5-3B-Instruct_lora_finetune
