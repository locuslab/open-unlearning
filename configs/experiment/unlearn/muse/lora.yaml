# @package _global_

defaults:
  - override /model: Qwen2.5-3B-Instruct-lora
  - override /trainer: GradAscent
  - override /data: unlearn
  - override /data/datasets@data.forget: MUSE_forget
  - override /data/datasets@data.retain: MUSE_retain
  - override /eval: muse

data_split: News
forget_split: forget
retain_split: retain1
retain_logs_path: null

model:
  model_args:
    pretrained_model_name_or_path: muse-bench/MUSE-${data_split}_target

data:
  anchor: forget
  forget:
    MUSE_forget: 
      args:
        hf_args:
          split: ${forget_split}
          path: muse-bench/MUSE-${data_split}
  retain:
    MUSE_retain:
      args:
        hf_args:
          path: muse-bench/MUSE-${data_split}
          split: ${retain_split}

eval:
  muse:
    data_split: ${data_split}
    retain_logs_path: ${retain_logs_path}
    overwrite: true

trainer:
  args:
    per_device_train_batch_size: 4
    gradient_accumulation_steps: 8
    learning_rate: 1e-4  # Higher learning rate for LoRA
    num_train_epochs: 5  # Fewer epochs for LoRA
    warmup_epochs: 0.1  # Shorter warmup for LoRA
    lr_scheduler_type: constant
    logging_steps: 10
    save_steps: 500
    eval_steps: 500
    evaluation_strategy: steps
    save_strategy: steps
    load_best_model_at_end: false  # Disable to avoid metric issues
    save_total_limit: 2
    remove_unused_columns: false
    dataloader_pin_memory: false
    seed: 42

task_name: muse_unlearn_lora
